<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Gemini Live ‚Äî Audio + Function Calling</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <style>
    body {
      background: #0b1220;
      color: #e6eef8;
      font-family: system-ui, -apple-system, Segoe UI, Roboto;
      padding: 20px;
    }
    h2 { margin-bottom: 8px; }

    .card {
      background: #071025;
      border: 1px solid #123041;
      border-radius: 10px;
      padding: 14px;
      margin-bottom: 14px;
    }

    label {
      font-weight: 600;
      display: block;
      margin-top: 10px;
      margin-bottom: 6px;
    }

    textarea {
      width: 100%;
      min-height: 120px;
      background: #041220;
      color: #e6eef8;
      border: 1px solid #123041;
      border-radius: 8px;
      padding: 10px;
      resize: vertical;
    }

    select, button {
      background: #0ea5a3;
      color: #002;
      border: none;
      padding: 10px 14px;
      border-radius: 8px;
      font-weight: 600;
      cursor: pointer;
      margin-right: 8px;
    }

    button.stop {
      background: #ef4444;
      color: white;
    }

    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }

    .status {
      margin-left: 8px;
      font-weight: 600;
      color: #9fe6e1;
    }

    .blackboard {
      background: #021826;
      border: 1px solid #123041;
      border-radius: 8px;
      padding: 12px;
      min-height: 80px;
    }

    .blackboard-line {
    opacity: 0;
    transform: translateY(10px);
    animation: fadeInUp 0.6s ease-out forwards;
    }

    .blackboard ul,
    .blackboard ol {
        margin: 0;
        padding-left: 20px;
    }

    .blackboard ul + ul,
    .blackboard ol + ol {
         margin-top: -10px; /* Remove gap between consecutive lists */
    }
    .blackboard mjx-container {
        color: #e6eef8 !important;
        margin: 8px 0;
    }

    .blackboard mjx-container[display="true"] {
        margin: 16px 0;
    }

    @keyframes fadeInUp {
    to {
        opacity: 1;
        transform: translateY(0);
    }
    }

    pre {
      background: #021018;
      padding: 12px;
      border-radius: 8px;
      overflow-x: auto;
      white-space: pre-wrap;
    }
  </style>
</head>

<body>
  <h2>Gemini Live ‚Äî Mixed Learning Player</h2>

  <div class="card">
    <label>Learner Level</label>
    <select id="learnerLevel">
      <option>Novice</option>
      <option selected>Competent</option>
      <option>Expert</option>
    </select>
    <label>Learning Content</label>
    <textarea id="content" placeholder="Paste module opening or sub-module content here..."></textarea>

    <div style="margin-top:12px">
  <button id="connectBtn">üîó Connect to Gemini</button>
  <button id="startBtn" disabled>‚ñ∂ Start Lesson</button>
  <button id="stopBtn" class="stop" disabled>‚èπ Stop & Disconnect</button>
  <span id="status" class="status">Disconnected</span>



  <div class="card">
    <h3>Blackboard (from function calls)</h3>
    <div id="blackboard" class="blackboard">Waiting for updates‚Ä¶</div>
  </div>

  <div class="card">
    <h3>Text Output (if any)</h3>
    <pre id="textOutput">(none)</pre>
  </div>

  
  <!-- ADD THIS NEW CARD -->
  <div class="card">
    <h3>üé§ Your Speech (Input Transcription)</h3>
    <div style="background: #041826; border: 1px solid #0ea5a3; border-radius: 8px; padding: 12px; min-height: 60px;">
      <div id="userTranscript" style="color: #9fe6e1; font-family: monospace; white-space: pre-wrap;">(Waiting for your voice...)</div>
    </div>
  </div>
</div>
  </div>
<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
<script type="module">
import {
  GoogleGenAI,
  Modality,
  Behavior,
  FunctionResponseScheduling,
  StartSensitivity,    
  EndSensitivity       
} from "https://esm.run/@google/genai";

/* ============================
   CONFIG
============================ */

const API_KEY = "API_KEY"; // üî¥ dev only
const MODEL = "gemini-2.5-flash-native-audio-preview-12-2025";

/* ============================
   STATE
============================ */

let session = null;
let stopped = false;
let stream = null;
let processor = null;

/* ============================
   UI ELEMENTS
============================ */

const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");
const statusEl = document.getElementById("status");
const blackboardEl = document.getElementById("blackboard");
const textOutputEl = document.getElementById("textOutput");
const userTranscriptEl = document.getElementById("userTranscript");
const connectBtn = document.getElementById("connectBtn");

// Use one consistent variable for audio
let audioCtx = null;
let nextStartTime = 0;
let audioOutputQueue = [];
let activeSources = [];
let blackboardQueue = [];
let isProcessingQueue = false;
const LINE_DISPLAY_DELAY = 0; 
/* ============================
   BLACKBOARD QUEUE PROCESSOR
============================ */
async function processBlackboardQueue() {
    if (isProcessingQueue || blackboardQueue.length === 0) return;
    
    isProcessingQueue = true;
    
    while (blackboardQueue.length > 0 && !stopped) {
        const item = blackboardQueue.shift();
        
        if (item.mode === 'replace') {
            // Clear blackboard for replace mode
            blackboardEl.innerHTML = '';
        }
        
        // Create wrapper for the line with animation
        const lineDiv = document.createElement('div');
        lineDiv.className = 'blackboard-line';
        lineDiv.innerHTML = item.html;
        
        // Add separator if appending (except for first item after replace)
        if (item.mode === 'append' && blackboardEl.children.length > 0 && !item.isList) {
            const hr = document.createElement('hr');
            hr.style.borderColor = '#123041';
            hr.style.margin = '10px 0';
            blackboardEl.appendChild(hr);
        }
        
        blackboardEl.appendChild(lineDiv);
        
        // ‚úÖ ADD THIS - Render MathJax for the new content
        if (typeof MathJax !== 'undefined' && MathJax.typesetPromise) {
            try {
                await MathJax.typesetPromise([lineDiv]);
            } catch (err) {
                console.warn('MathJax rendering error:', err);
            }
        }
        
        // Auto-scroll to show new content
        blackboardEl.scrollTop = blackboardEl.scrollHeight;
        
        // Wait before showing next line
        if (blackboardQueue.length > 0) {
            await new Promise(resolve => setTimeout(resolve, LINE_DISPLAY_DELAY));
        }
    }
    
    isProcessingQueue = false;
}


function getAudioContext() {
    if (!audioCtx || audioCtx.state === 'closed') {
        // Let browser use its default sample rate (usually 48kHz)
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    }
    return audioCtx;
}

const updateBlackboard = {
    name: "update_blackboard",
    description: "Updates the visual blackboard. IMPORTANT: When in middle of a lesson, only send NEW content that hasn't been shown yet. when starting a new lesson, send single point/title content at a time for the new lesson.",
    behavior: Behavior.NON_BLOCKING,
    parameters: {
        type: "object",
        properties: {
            markdown: { type: "string", description: "The text content (NEW content only when appending)" },
            mode: { type: "string", enum: ["append", "replace"], description: "Use 'replace' to clear and start fresh, 'append' to add new content" }
        },
        required: ["markdown", "mode"]
    }
};

/* ============================
   INIT CLIENT
============================ */

const ai = new GoogleGenAI({ apiKey: API_KEY });

let MIX_PROMPT_CONTENT = `

## 1. INPUTS PROVIDED TO YOU

### 1.1 Source Content
A **complete text-based learning module**.

### 1.2 Learner Context
* Learner Level: '{Novice | Competent | Expert}'
* Adapt **depth, pacing, and language** accordingly

---

## 2. OUTPUT CHANNELS

### 2.1 AUDIO (Primary)
Deliver lessons through **spoken explanation**:
* Conversational tone with contractions
* Frequent signposting
* Speak for the **ear**, not the eye

### 2.2 BLACKBOARD (Secondary)
**Call 'update_blackboard(markdown=...)' frequently** with:
* Headings, bullet points, frameworks, step lists
* **ONE LINE AT A TIME** - keep minimal and scannable
* Sync with audio - never show content before explaining it

---

## 3. BLACKBOARD TEMPLATE

Always follow this structure (add **one line per update**):

~~~markdown
## [Topic Name]

- Point 1: ‚Ä¶
- Point 2: ‚Ä¶
- Point 3: ‚Ä¶
~~~

---

## 4. MATHEMATICAL FORMULAS

Use MathJax/LaTeX syntax:
* Inline: '$E = mc^2$''
* Display: '$$x = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}$$'
* Common: '$\alpha, \beta, \sum_{i=1}^{n}, \int_a^b, \lim_{x \to \infty}$'

---

## 5. TEACHING FLOW

**Cycle (repeat until module complete):**
1. Call 'update_blackboard' with next point
2. Explain in audio (thoroughly and detailed)
3. Move to next point

**After module:** Ask for questions and answer immediately

**CRITICAL:** Board and audio must stay synchronized and consistent - NEVER GET AHEAD OR FALL BEHIND.

---

## 6. AUDIO DELIVERY

* Refer to blackboard indirectly: *"What you see on the board‚Ä¶"*
* Maintain momentum with explicit transitions
* **Never read the blackboard verbatim**
* AFTER RECAP IS DONE, Ask the learner to write down key points in their own words OR make a sticky note, indicate that you will pause until they say they are ready to continue the lesson.


---

## 7. CRITICAL REMINDERS
1. **No redundant audio/text** - different roles for each modality
2. **Frequent updates** - one line per blackboard call
3. **Adapt to learner level** - adjust depth and pacing
4. **Tool calls are NON-BLOCKING**

`;

// Store lesson state
let lessonState = {
    learnerLevel: '',
    content: '',
    isActive: false
};

// Auto-reconnect function
async function reconnectSession() {
    if (!lessonState.isActive) return;
    
    console.log("Attempting to reconnect...");
    statusEl.textContent = "Reconnecting...";
    
    // ‚úÖ Clean up old session first
    await cleanupSession();
    
    try {
        // Don't call connectBtn.onclick() - create session directly
        await connectBtn.onclick();
        
        await new Promise(resolve => setTimeout(resolve, 500));
        
        if (lessonState.isActive && session) {
            await resumeLesson();
        }
    } catch (e) {
        console.error("Reconnection failed:", e);
        // Don't auto-retry - let user manually reconnect
        statusEl.textContent = "Reconnection failed - please reconnect manually";
        resetUI();
    }
}
async function resumeLesson() {
    // Restart microphone
    await startMic();
    
    const prompt = `
    [RECONNECTION CONTEXT]
    The session was interrupted. Please continue from where we left off.

    Content: ${lessonState.content}
    Learner Level: ${lessonState.learnerLevel}
    
        

    
    Please acknowledge and continue the lesson naturally.
    `;
    
    await session.sendClientContent({ 
        turns: [{ 
            role: "user", 
            parts: [{ text: prompt }] 
        }] 
    });
    
    statusEl.textContent = "üé§ Lesson Resumed - Listening...";
}

let isModelSpeaking = false;
function handleMessage(message) {
    if (stopped) return;

    // Track speaking state
    if (message.serverContent?.turnComplete) {
        isModelSpeaking = false;
        console.log("‚úÖ Model finished speaking");
    } else if (message.data) {
        isModelSpeaking = true;
    }

    // Handle interruption
    if (message.serverContent?.interrupted) {
        console.log("‚ö†Ô∏è Generation was interrupted - clearing audio queue");
        
        // ‚úÖ Stop all active audio
        activeSources.forEach(source => {
            try {
                source.stop();
                source.disconnect();
            } catch (e) {
                // Ignore if already stopped
            }
        });
        activeSources = [];
        
        nextStartTime = 0;
        return;
    }
        // Handle audio output from Gemini (24kHz)

    if (message.data) {
        try {
            const ctx = getAudioContext();
            
            const pcmBytes = Uint8Array.from(atob(message.data), c => c.charCodeAt(0));
            const pcm16 = new Int16Array(pcmBytes.buffer);
            
            const buffer = ctx.createBuffer(1, pcm16.length, 24000);
            const channelData = buffer.getChannelData(0);
            
            for (let i = 0; i < pcm16.length; i++) {
                channelData[i] = pcm16[i] / 32768.0;
            }

            const source = ctx.createBufferSource();
            source.buffer = buffer;
            source.connect(ctx.destination);

            // ‚úÖ ADD THIS - Track the source
            activeSources.push(source);
            
            // ‚úÖ ADD THIS - Remove from tracking when it ends
            source.onended = () => {
                const index = activeSources.indexOf(source);
                if (index > -1) {
                    activeSources.splice(index, 1);
                }
            };

            if (nextStartTime < ctx.currentTime) {
                nextStartTime = ctx.currentTime;
            }
            source.start(nextStartTime);
            nextStartTime += buffer.duration;
            
        } catch (error) {
            console.error("Audio playback error:", error);
        }
    }

    // Handle text output
    if (message.serverContent?.modelTurn?.parts) {
        for (const part of message.serverContent.modelTurn.parts) {
            if (part.text) {
                textOutputEl.textContent = part.text;
            }
        }
    }

    // ADD THIS SECTION - Handle input transcription (your speech)
    if (message.serverContent?.inputTranscription) {
        const transcript = message.serverContent.inputTranscription.text;
        console.log("üé§ Your speech:", transcript);
        
        // Append new transcription with timestamp
        const timestamp = new Date().toLocaleTimeString();
        const currentText = userTranscriptEl.textContent;
        
        if (currentText === "(Waiting for your voice...)") {
            userTranscriptEl.textContent = `[${timestamp}] You: ${transcript}`;
        } else {
            userTranscriptEl.textContent = `${currentText}\n\n[${timestamp}] You: ${transcript}`;
        }
        
        // Auto-scroll to bottom
        userTranscriptEl.scrollTop = userTranscriptEl.scrollHeight;
    }

        // Handle tool calls
    if (message.toolCall) {
        const responses = [];
        for (const fc of message.toolCall.functionCalls) {
            if (fc.name === "update_blackboard") {
                const md = fc.args?.markdown ?? "";
                const mode = fc.args?.mode ?? "append";
                
                try {
                    // Parse markdown to HTML
                    const html = marked.parse(md);
                    
                    // ‚úÖ FIXED - Avoid duplicate content
                    const tempDiv = document.createElement('div');
                    tempDiv.innerHTML = html;
                    
                    // Get all top-level elements
                    const elements = Array.from(tempDiv.children);
                    
                    // ‚úÖ NEW - Track existing content to avoid duplicates
                    const existingContent = new Set();
                    if (mode === 'append') {
                        // Get text content of existing blackboard items
                        Array.from(blackboardEl.querySelectorAll('.blackboard-line')).forEach(el => {
                            const text = el.textContent.trim();
                            if (text) existingContent.add(text);
                        });
                    }
                    
                    let isFirstItem = true;
                    
                    // Process each element
                    elements.forEach((el) => {
                        const elementText = el.textContent.trim();
                        
                        // ‚úÖ Skip if content already exists (for append mode)
                        if (mode === 'append' && existingContent.has(elementText)) {
                            console.log(`‚è≠Ô∏è Skipping duplicate content: ${elementText.substring(0, 50)}...`);
                            return; // Skip this element
                        }
                        
                        if (el.tagName === 'UL' || el.tagName === 'OL') {
                            // For lists, split into individual items
                            const listType = el.tagName.toLowerCase();
                            const listItems = Array.from(el.querySelectorAll('li'));
                            
                            listItems.forEach((li) => {
                                const liText = li.textContent.trim();
                                
                                // ‚úÖ Check each list item for duplicates
                                if (mode === 'append' && existingContent.has(liText)) {
                                    console.log(`‚è≠Ô∏è Skipping duplicate list item: ${liText.substring(0, 50)}...`);
                                    return;
                                }
                                
                                // Wrap each item in its own list for valid HTML
                                const wrapper = document.createElement(listType);
                                wrapper.appendChild(li.cloneNode(true));
                                
                                blackboardQueue.push({
                                    html: wrapper.outerHTML,
                                    mode: isFirstItem ? mode : 'append',
                                    isList: true
                                });
                                isFirstItem = false;
                            });
                        } else {
                            // For other elements (headings, paragraphs), add as-is
                            blackboardQueue.push({
                                html: el.outerHTML,
                                mode: isFirstItem ? mode : 'append',
                                isList: false
                            });
                            isFirstItem = false;
                        }
                    });
                    
                    // Start processing queue
                    processBlackboardQueue();
                    
                } catch (error) {
                    console.error("Markdown parsing error:", error);
                }

                responses.push({
                    id: fc.id,
                    name: fc.name,
                    response: { 
                        result: "ok", 
                        scheduling: FunctionResponseScheduling.SILENT 
                    }
                });
            }
        }
        
        if (responses.length) {
            session.sendToolResponse({ functionResponses: responses });
        }
    }
}

function resetUI() {
    connectBtn.disabled = false;
    startBtn.disabled = true;
    stopBtn.disabled = true;
}
async function cleanupSession() {
    console.log("üßπ Cleaning up existing session...");

    blackboardQueue = [];
    isProcessingQueue = false;
    
    // ‚úÖ REORDERED - Disconnect processor FIRST to stop audio processing immediately
    if (processor) {
        processor.disconnect();
        processor.onaudioprocess = null; // Remove handler
        processor = null;
        console.log("Audio processor disconnected");
    }
    
    // ‚úÖ Stop all active audio sources
    console.log(`Stopping ${activeSources.length} active audio sources...`);
    activeSources.forEach(source => {
        try {
            source.stop();
            source.disconnect();
        } catch (e) {
            // Source might have already ended
        }
    });
    activeSources = []; // Clear the array
    
    // Stop microphone
    if (stream) {
        stream.getTracks().forEach(track => {
            track.stop();
            console.log("Stopped track:", track.kind);
        });
        stream = null;
    }
    
    // Close session LAST (after all audio operations stopped)
    if (session) {
        try {
            session.close();
            console.log("Session closed");
        } catch (e) {
            console.warn("Session close error:", e);
        }
        session = null;
    }
    
    // Reset audio playback
    nextStartTime = 0;
}

stopBtn.onclick = async () => {
    console.log("üõë Stopping session...");
    stopped = true;
    lessonState.isActive = false;
    statusEl.textContent = "Disconnecting‚Ä¶";

    await cleanupSession();
    
    // Close audio context (optional - can keep for faster restart)
    if (audioCtx && audioCtx.state !== 'closed') {
        await audioCtx.close();
        audioCtx = null;
    }

    userTranscriptEl.textContent = "(Waiting for your voice...)";
    statusEl.textContent = "Disconnected";
    resetUI();
};

connectBtn.onclick = async () => {
    // ‚úÖ PREVENT DUPLICATE SESSIONS
    if (session) {
        console.warn("‚ö†Ô∏è Session already exists. Cleaning up first...");
        await cleanupSession();
    }
    
    statusEl.textContent = "Connecting‚Ä¶";
    stopped = false;

    try {
        session = await ai.live.connect({
            model: MODEL,
            config: {
                responseModalities: [Modality.AUDIO],
                tools: [{ functionDeclarations: [updateBlackboard] }],
                inputAudioTranscription: {},  
                thinkingConfig: {
                    thinkingBudget: 256,
                },
                realtimeInputConfig: {
                    automaticActivityDetection: {
                        disabled: false, // default
                        startOfSpeechSensitivity: StartSensitivity.START_SENSITIVITY_LOW,
                        endOfSpeechSensitivity: EndSensitivity.END_SENSITIVITY_LOW,
                        prefixPaddingMs: 50,
                        silenceDurationMs: 200,
                    }
                },
                systemInstruction: {
                    parts: [{
                        text: `## ROLE

You are an **Adaptive Multimodal Tutor** named **Atlas** delivering instruction through:

* **Real-time spoken audio** (primary teaching channel)
* **Structured visual updates** via the 'update_blackboard' tool (secondary channel)

Your task is to **explain the provided learning content** using **audio narration** while **progressively updating the blackboard** with concise, structured text.
If any content isn't provided, Introduce yourself by simply saying "Hello, Am Atlas" ONLY, then ask the learner if they need any help.
DO NOT SAY THAT YOU ARE AN ADAPTIVE MULTIMODAL TUTOR.
IMPORTANT: Always Use the 'update_blackboard' tool before speaking.

${MIX_PROMPT_CONTENT}
`
                    }]
                }
            },
            callbacks: {
                onopen: () => {
                    console.log("‚úÖ WebSocket Handshake Complete");
                },
                onmessage: (msg) => {
                    console.log("üì® Message received:", msg);
                    handleMessage(msg);
                },
                onerror: (e) => {
                    console.error("‚ùå Live Error:", e);
                    stopped = true; // ‚úÖ ADD THIS - Stop processing immediately
                    statusEl.textContent = "Error: " + e.message;
                },
                onclose: (e) => {
                    console.log("üîå Session closed:", e.reason);
                    stopped = true; // ‚úÖ ADD THIS - Stop processing immediately
                    if (!lessonState.isActive) {
                        statusEl.textContent = "Disconnected";
                        resetUI();
                    } else {
                        statusEl.textContent = "Disconnected unexpectedly";
                        resetUI();
                    }
                }
            }
        });

        console.log("üöÄ Session initialized and assigned.");
        
        await session.sendClientContent({ 
            turns: [{ 
                role: "user", 
                parts: [{ text: "Introduce yourself and your purpose." }] 
            }],
            turnComplete: true
        });

        statusEl.textContent = "Connected - Ready to Start";
        connectBtn.disabled = true;
        startBtn.disabled = false;
        stopBtn.disabled = false;

    } catch (e) {
        statusEl.textContent = "Connection Failed: " + e.message;
        console.error("Connection error:", e);
        await cleanupSession(); // Clean up on error
        resetUI();
    }
};

async function startMic() {
    // ‚úÖ PREVENT DUPLICATE MIC STREAMS
    if (processor || stream) {
        console.warn("‚ö†Ô∏è Microphone already active. Stopping old stream...");
        if (processor) {
            processor.disconnect();
            processor.onaudioprocess = null;
            processor = null;
        }
        if (stream) {
            stream.getTracks().forEach(t => t.stop());
            stream = null;
        }
    }
    
    try {
        const ctx = getAudioContext();
        
        if (ctx.state === 'suspended') {
            await ctx.resume();
        }

        stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            } 
        });
        
        const source = ctx.createMediaStreamSource(stream);
        
        const bufferSize = 16384;
        processor = ctx.createScriptProcessor(bufferSize, 1, 1);
        processor.onaudioprocess = (e) => {
            // ‚úÖ Enhanced checks - check stopped first, then session existence AND validity
            if (stopped || !session) return;
            
            // ‚úÖ Additional safety check - verify session is connected
            try {
                const inputData = e.inputBuffer.getChannelData(0);
                const pcm16 = new Int16Array(inputData.length);
                
                for (let i = 0; i < inputData.length; i++) {
                    const s = Math.max(-1, Math.min(1, inputData[i]));
                    pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                }
                
                const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                
                // ‚úÖ Double-check session before sending (race condition protection)
                if (!stopped && session) {
                    session.sendRealtimeInput({
                        audio: {
                            data: base64,
                            mimeType: `audio/pcm;rate=${Math.round(ctx.sampleRate)}`
                        }
                    });
                }
            } catch (err) {
                // ‚úÖ Silently handle errors when session is closing
                if (!stopped) {
                    console.error("Error sending audio:", err);
                }
            }
        };
        source.connect(processor);
        processor.connect(ctx.destination);
        
        console.log(`üé§ Microphone active - streaming at ${ctx.sampleRate}Hz to Gemini`);
        
    } catch (error) {
        console.error("Microphone error:", error);
        alert("Could not access microphone: " + error.message);
    }
}

/* ============================
   START LIVE SESSION
============================ */
startBtn.onclick = async () => {
    const learnerLevel = document.getElementById("learnerLevel").value;
    const content = document.getElementById("content").value.trim();

    if (!content) {
        alert("Please provide content first.");
        return;
    }

    // Save state
    lessonState = {
        learnerLevel,
        content,
        isActive: true
    };

    await startMic();
    // START MICROPHONE NOW
    userTranscriptEl.textContent = "(Listening...)";

    const prompt = `
    
    Here is the content of Module Opening / Sub-Module that you are suppose to explain to the learner:
    ${content}

    IMPORTANT ‚Äî Learner Profile (Context):
    ‚Ä¢ Job Role: Business Analyst  
    ‚Ä¢ Company: Nagarro  
    ‚Ä¢ Industry: Technology  
    ‚Ä¢ Learner Level: ${learnerLevel}  
    ‚Ä¢ Primary Context: Desk  
    ‚Ä¢ Audio Preference: Low  

    **CONTENT RULES:** - The blackboard must stay visible. 
       - If you move to a new topic, you MUST call 'update_blackboard' again with 'append' mode to show the new key terms.
    
    NOTE: YOU MUST LISTEN for the user's voice. If they ask a question, answer it immediately. Treat this as a real-time 1-on-1 coaching session.
    DO NOT SPEAK UNTIL THE BOARD IS UPDATED.
    `;

    // Send the prompt to start the lesson
    await session.sendClientContent({ 
        turns: [{ 
            role: "user", 
            parts: [{ text: prompt }] 
        }] 
    });
    
    startBtn.disabled = true; // Disable start button during lesson
    statusEl.textContent = "üé§ Lesson Active - Speak to interact!";
};
 

</script>
</body>
</html>
